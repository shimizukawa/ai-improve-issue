"""Graphå‡¦ç†ãƒãƒ¼ãƒ‰å®šç¾© - pydantic-graphå®Ÿè£…"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from typing import Annotated

from pydantic_graph import BaseNode, End, Edge, GraphRunContext

from .config import AppSettings, EnvConfig, load_template_content
from .llm_factory import LLMFactory
from .models import IssueData
from .rag_client import create_issue_chunks


@dataclass
class GraphState:
    """Graphã®çŠ¶æ…‹ã‚’ç®¡ç†"""

    issue_number: int
    issue_title: str
    issue_body: str
    is_rag_enabled: bool
    settings: AppSettings
    env_config: EnvConfig
    dry_run: bool = False

    # ä¸­é–“çµæœ
    similar_issues: list = field(default_factory=list)
    template_name: str | None = None
    improved_content: str | None = None


@dataclass
class FetchIssueState:
    """Issueå–å¾—ã®çŠ¶æ…‹"""

    issue_number: int
    env_config: EnvConfig
    fetched_issue: IssueData | None = None


@dataclass
class FetchIssueNode(BaseNode[FetchIssueState, None, dict]):
    """Issueå–å¾—ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[FetchIssueState]
    ) -> Annotated[End[dict], Edge(label="Issueå–å¾—å®Œäº†")]:
        """GitHub APIã‹ã‚‰Issueæƒ…å ±ã‚’å–å¾—"""
        print(f"Fetching issue #{ctx.state.issue_number}...")
        github_issue_tool = ctx.tools["github_issue"]
        issue = github_issue_tool.fetch_issue(ctx.state.issue_number)

        if not issue:
            return End({"status": "error", "issue_number": ctx.state.issue_number})

        ctx.state.fetched_issue = issue
        return End(
            {
                "status": "success",
                "issue_number": issue.number,
                "title": issue.title,
            }
        )


@dataclass
class FetchAllIssuesState:
    """å…¨Issueå–å¾—ã®çŠ¶æ…‹"""

    start: int
    end: int | None
    env_config: EnvConfig
    fetched_issues: list[IssueData] = field(default_factory=list)


@dataclass
class InputValidationNode(BaseNode[GraphState]):
    """å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> (
        Annotated[RAGSearchNode, Edge(label="RAGæ¤œç´¢å®Ÿè¡Œ")]
        | Annotated[TemplateDetectionNode, Edge(label="ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šã¸")]
    ):
        """å…¥åŠ›æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        print(f"Processing issue #{ctx.state.issue_number}")
        print(f"Title: {ctx.state.issue_title}")
        print(f"Body length: {len(ctx.state.issue_body)} characters")

        # 10æ–‡å­—æœªæº€ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        combined = (ctx.state.issue_title or "") + (ctx.state.issue_body or "")
        text_without_spaces = (
            combined.replace(" ", "").replace("\n", "").replace("\t", "")
        )

        if len(text_without_spaces) < 10:
            raise ValueError(
                f"Issue #{ctx.state.issue_number} does not need improvement (too short)"
            )

        # RAGæœ‰åŠ¹ãªã‚‰RAGæ¤œç´¢ã¸ã€ç„¡åŠ¹ãªã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šã¸
        if ctx.state.is_rag_enabled:
            return RAGSearchNode()
        else:
            return TemplateDetectionNode()


@dataclass
class RAGSearchNode(BaseNode[GraphState]):
    """RAGæ¤œç´¢ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> Annotated[TemplateDetectionNode, Edge(label="é¡ä¼¼Issueæ¤œç´¢å®Œäº†")]:
        print("RAG mode: Enabled")

        embedding_tool = ctx.tools["embedding"]
        vector_search_tool = ctx.tools["vector_search"]
        SimilarIssue = ctx.state.settings.rag.similar_issue_class

        vector_search_tool.ensure_collection()
        query_text = f"{ctx.state.issue_title}\n{ctx.state.issue_body}"
        query_vector = embedding_tool.generate_embedding(query_text)
        similar_issues = vector_search_tool.search_similar_issues(
            query_vector,
            limit=ctx.state.settings.rag.top_k,
            exclude_issue_number=ctx.state.issue_number,
            SimilarIssue=SimilarIssue,
        )
        ctx.state.similar_issues = similar_issues
        if similar_issues:
            print(f"Found {len(similar_issues)} similar issues")
            for i, sim in enumerate(similar_issues, 1):
                print(
                    f"  {i}. #{sim.issue_number}: {sim.issue_title[:50]}... "
                    f"(similarity: {sim.similarity:.1%})"
                )
        else:
            print("No similar issues found")
        return TemplateDetectionNode()


@dataclass
class TemplateDetectionNode(BaseNode[GraphState]):
    """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> Annotated[ContentGenerationNode, Edge(label="ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šå®Œäº†")]:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ¤å®šã‚’å®Ÿè¡Œ"""
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæƒ…å ±ã‚’è¦ç´„
        tmpl_summaries = []
        for name, tmpl in ctx.state.settings.templates.items():
            sp = (tmpl.system_prompt or "").strip()
            if len(sp) > 300:
                sp = sp[:300]
            kws = (tmpl.keywords or [])[:10]
            tmpl_summaries.append(
                {
                    "name": name,
                    "keywords": kws,
                    "system_prompt": sp,
                }
            )

        prompt = (
            "ã€Issueã€‘\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«: {ctx.state.issue_title}\n"
            f"æœ¬æ–‡: {ctx.state.issue_body}\n\n"
            "ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå€™è£œä¸€è¦§(JSON)ã€‘\n"
            f"{json.dumps(tmpl_summaries, ensure_ascii=False)}\n\n"
            "ä»¥ä¸‹ã®å½¢å¼ã§å³å¯†ã«1ä»¶ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
            '{"template": "<name>"}'
        )

        # Pydantic AI Agentå®Ÿè¡Œ
        print("LLM: Detecting template...")
        agent = LLMFactory.create_template_detection_agent(ctx.state.settings)
        result = await agent.run(prompt)

        template_name = result.data.template
        if not ctx.state.settings.validate_template(template_name):
            print(
                f"ä¸æ˜ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå '{template_name}'ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
            )
            template_name = ctx.state.settings.default_template

        ctx.state.template_name = template_name
        print(f"Detected template: {template_name}")

        return ContentGenerationNode()


@dataclass
class ContentGenerationNode(BaseNode[GraphState]):
    """æ–‡ç« ç”Ÿæˆãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> Annotated[CommentFormattingNode, Edge(label="LLMæ–‡ç« ç”Ÿæˆå®Œäº†")]:
        """æ–‡ç« ç”Ÿæˆã‚’å®Ÿè¡Œ"""
        if not ctx.state.template_name:
            ctx.state.template_name = ctx.state.settings.default_template

        tmpl = ctx.state.settings.templates[ctx.state.template_name]
        template_content = load_template_content(tmpl)

        system_prompt = f"""
{tmpl.system_prompt}

ã€Issueè¨˜è¿°ã€‘ã«ã¤ã„ã¦ã€ã€é¡ä¼¼ã™ã‚‹éå»Issueã€‘ã®å†…å®¹ã‚’å‚è€ƒã«ã—ã¦ã€æ¦‚è¦ã‚’æ•¬ä½“ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
ã¾ãŸã€ã€é¡ä¼¼ã™ã‚‹éå»Issueã€‘ã«é¡ä¼¼ã™ã‚‹å†…å®¹ãŒã‚ã‚‹ã‹åˆ¤å®šã—ã€ã€## é¡ä¼¼Issueã€‘ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ãã®idã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ã‚‚ã—å­˜åœ¨ã—ãªã„å ´åˆã¯ã€Œãªã—ã€ã¨å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›å½¢å¼ä»¥å¤–ã®æ–‡ç« ã¯ä¸è¦ã§ã™ã€‚
"""

        prompt = f"""
ã€Issueè¨˜è¿°ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {ctx.state.issue_title}
æœ¬æ–‡: {ctx.state.issue_body}

ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘
{template_content}
"""

        # RAGæ¤œç´¢çµæœãŒã‚ã‚Œã°è¿½åŠ 
        if ctx.state.similar_issues and len(ctx.state.similar_issues) > 0:
            similar_info = (
                "\n\nã€é¡ä¼¼ã™ã‚‹éå»Issueã€‘\nä»¥ä¸‹ã®éå»Issueã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼š\n"
            )
            for i, issue in enumerate(ctx.state.similar_issues, 1):
                similar_info += f"""
ã€å‚è€ƒIssue {i}ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: {issue.issue_title}
- æœ¬æ–‡æŠœç²‹: {issue.issue_body[:200]}...
- é¡ä¼¼åº¦: {issue.similarity:.1%}
"""
            similar_info += "\nä¸Šè¨˜ã®å‚è€ƒIssueã‹ã‚‰ã€è¨˜è¿°ã‚¹ã‚¿ã‚¤ãƒ«ã‚„å¿…è¦ãªæƒ…å ±é …ç›®ã‚’å­¦ã³ã€ã‚ˆã‚Šå…·ä½“çš„ã§å®Ÿç”¨çš„ãªä¾‹æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
            prompt += similar_info

        # Pydantic AI Agentå®Ÿè¡Œ
        print("LLM: Generating content...")
        agent = LLMFactory.create_content_generation_agent(
            ctx.state.settings, system_prompt
        )
        result = await agent.run(prompt)

        ctx.state.improved_content = result.data
        print("Content generated successfully")

        return CommentFormattingNode()


@dataclass
class CommentFormattingNode(BaseNode[GraphState]):
    """ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> Annotated[PostCommentNode, Edge(label="ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®Œäº†")]:
        """ã‚³ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å®Ÿè¡Œ"""
        print("Formatting comment...")

        template_display_names = {
            "feature_request": "æ©Ÿèƒ½è¦ä»¶",
            "bug_report": "ãƒã‚°å ±å‘Š",
        }
        template_name = ctx.state.template_name or ctx.state.settings.default_template
        template_display = template_display_names.get(template_name, template_name)

        comment = f"""## ğŸ¤– AIã«ã‚ˆã‚‹Issueè¨˜å…¥ä¾‹

**é¸å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: {template_display}

---

{ctx.state.improved_content}

---
"""

        # RAGæ¤œç´¢çµæœãŒã‚ã‚Œã°è¿½åŠ 
        if ctx.state.similar_issues and len(ctx.state.similar_issues) > 0:
            comment += "\n### ğŸ“š å‚è€ƒã«ã—ãŸé¡ä¼¼Issue\n\nã“ã®ä¾‹æ–‡ã¯ä»¥ä¸‹ã®éå»Issueã‚’å‚è€ƒã«ç”Ÿæˆã—ã¦ã„ã¾ã™ï¼š\n\n"
            for i, issue in enumerate(ctx.state.similar_issues, 1):
                comment += f"""{i}. **#{issue.issue_number}: {issue.issue_title}** ({issue.state})
   - é¡ä¼¼åº¦: {issue.similarity:.0%}
   - {issue.url}

"""
            comment += "---\n\n"

        comment += (
            """ğŸ’¡ **ä½¿ã„æ–¹**: ä¸Šè¨˜ã®ä¾‹æ–‡ã‚’å‚è€ƒã«ã€Issueæœ¬æ–‡ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚"""
        )
        if ctx.state.similar_issues and len(ctx.state.similar_issues) > 0:
            comment += "é¡ä¼¼Issueã‚‚ç¢ºèªã™ã‚‹ã¨ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"
        else:
            comment += "å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«åˆã‚ã›ã¦å†…å®¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"

        comment += "\n\n<!-- AI-generated comment -->\n"

        # çŠ¶æ…‹ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä¿å­˜
        ctx.state.improved_content = comment

        return PostCommentNode()


@dataclass
class PostCommentNode(BaseNode[GraphState, None, dict]):
    """ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> (
        Annotated[IndexCurrentIssueNode, Edge(label="RAGç™»éŒ²å‡¦ç†ã¸")]
        | Annotated[End[dict], Edge(label="å‡¦ç†å®Œäº†")]
    ):
        """ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã¨æ¡ä»¶åˆ†å²"""
        comment = ctx.state.improved_content

        # dry-runãƒ¢ãƒ¼ãƒ‰: ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if ctx.state.dry_run:
            print("\n" + "=" * 60)
            print("[DRY RUN] ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            print("=" * 60)
            print(comment)
            print("=" * 60)
            return End(
                {
                    "status": "dry_run",
                    "issue_number": ctx.state.issue_number,
                    "comment_length": len(comment),
                }
            )

        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: GitHub CLIçµŒç”±ã§ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
        print(f"Posting comment to issue #{ctx.state.issue_number}...")

        github_issue_tool = ctx.tools["github_issue"]
        github_issue_tool.post_comment(ctx.state.issue_number, comment)

        # RAGæœ‰åŠ¹åˆ¤å®š
        if ctx.state.is_rag_enabled:
            return IndexCurrentIssueNode()
        else:
            return End(
                {
                    "status": "comment_posted",
                    "issue_number": ctx.state.issue_number,
                    "comment_length": len(comment),
                }
            )


@dataclass
class IndexCurrentIssueNode(BaseNode[GraphState, None, dict]):
    """é€šå¸¸ãƒ¢ãƒ¼ãƒ‰å¾Œã®RAGç™»éŒ²ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[GraphState]
    ) -> Annotated[End[dict], Edge(label="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²å®Œäº†")]:
        """ç¾åœ¨ã®Issueã‚’RAGã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"""
        print("Indexing current issue to RAG...")

        issue = IssueData(
            number=ctx.state.issue_number,
            title=ctx.state.issue_title,
            body=ctx.state.issue_body,
            state="open",
            url=(
                f"https://github.com/{ctx.state.env_config.github_repository}/issues/{ctx.state.issue_number}"
                if ctx.state.env_config.github_repository
                else ""
            ),
            labels=[],
        )

        embedding_tool = ctx.tools["embedding"]
        vector_search_tool = ctx.tools["vector_search"]
        vector_search_tool.ensure_collection()
        chunks = create_issue_chunks(issue.title, issue.body)
        vectors = embedding_tool.generate_embeddings_batch(chunks)
        vector_search_tool.upsert_issue_chunks(
            issue_number=issue.number,
            chunks=chunks,
            vectors=vectors,
            title=issue.title,
            state=issue.state,
            url=issue.url,
            labels=issue.labels,
        )
        print(f"âœ“ Issue indexed successfully ({len(chunks)} chunks)")

        return End(
            {
                "status": "indexed",
                "issue_number": ctx.state.issue_number,
                "chunks_indexed": len(chunks),
            }
        )


# ===== RAG Indexing Mode =====


@dataclass
class RAGIndexState:
    """RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®çŠ¶æ…‹"""

    issues: list[IssueData]
    settings: AppSettings
    env_config: EnvConfig
    current_index: int = 0

    # ä¸­é–“çµæœ
    success_count: int = 0
    total_issues: int = field(default_factory=lambda: 0)

    def __post_init__(self):
        if self.total_issues == 0:
            self.total_issues = len(self.issues)


@dataclass
class RAGIndexInitNode(BaseNode[RAGIndexState]):
    """RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆæœŸåŒ–ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[RAGIndexState]
    ) -> Annotated[RAGIndexProcessNode, Edge(label="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡¦ç†é–‹å§‹")]:
        """Qdrantæ¥ç¶šç¢ºèª"""
        print("=== RAG Indexing Mode ===")
        print(f"Total issues to index: {ctx.state.total_issues}")

        vector_search_tool = ctx.tools["vector_search"]
        vector_search_tool.ensure_collection()

        return RAGIndexProcessNode()


@dataclass
class RAGIndexProcessNode(BaseNode[RAGIndexState]):
    """RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡¦ç†ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[RAGIndexState]
    ) -> (
        Annotated[RAGIndexProcessNode, Edge(label="æ¬¡ã®Issueå‡¦ç†")]
        | Annotated[RAGIndexCompleteNode, Edge(label="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†")]
    ):
        """Issueå˜ä½ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡¦ç†"""
        if ctx.state.current_index >= ctx.state.total_issues:
            return RAGIndexCompleteNode()

        issue = ctx.state.issues[ctx.state.current_index]
        print(
            f"[{ctx.state.current_index + 1}/{ctx.state.total_issues}] "
            f"Indexing issue #{issue.number}..."
        )

        embedding_tool = ctx.tools["embedding"]
        vector_search_tool = ctx.tools["vector_search"]
        chunks = create_issue_chunks(issue.title, issue.body)
        vectors = embedding_tool.generate_embeddings_batch(chunks)
        print(f"Qdrant: Upserting issue #{issue.number}...")
        vector_search_tool.upsert_issue_chunks(
            issue_number=issue.number,
            chunks=chunks,
            vectors=vectors,
            title=issue.title,
            state=issue.state,
            url=issue.url,
            labels=issue.labels,
        )

        # æ¬¡ã®Issueã¸
        ctx.state.current_index += 1
        ctx.state.success_count += 1

        return RAGIndexProcessNode()


@dataclass
class RAGIndexCompleteNode(BaseNode[RAGIndexState, None, dict]):
    """RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[RAGIndexState]
    ) -> Annotated[End[dict], Edge(label="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œäº†")]:
        """å®Œäº†ãƒ­ã‚°å‡ºåŠ›"""
        print("\n=== Indexing Complete ===")
        print(f"Success: {ctx.state.success_count}/{ctx.state.total_issues} issues")

        return End(
            {
                "success": ctx.state.success_count,
                "total": ctx.state.total_issues,
            }
        )


# ===== Single Issue Update Mode =====


@dataclass
class SingleIssueUpdateState:
    """å˜ä¸€Issueæ›´æ–°ãƒ¢ãƒ¼ãƒ‰ã®çŠ¶æ…‹"""

    issue: IssueData
    settings: AppSettings
    env_config: EnvConfig


@dataclass
class SingleIssueUpdateNode(BaseNode[SingleIssueUpdateState, None, dict]):
    """å˜ä¸€Issueæ›´æ–°ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[SingleIssueUpdateState]
    ) -> Annotated[End[dict], Edge(label="Issueæ›´æ–°å®Œäº†")]:
        """å˜ä¸€Issueã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹Broadcast"""
        issue = ctx.state.issue
        print(f"=== Update Single Issue #{issue.number} ===")

        embedding_tool = ctx.tools["embedding"]
        vector_search_tool = ctx.tools["vector_search"]
        vector_search_tool.ensure_collection()
        chunks = create_issue_chunks(issue.title, issue.body)
        vectors = embedding_tool.generate_embeddings_batch(chunks)
        print(f"Qdrant: Upserting issue #{issue.number}...")
        vector_search_tool.upsert_issue_chunks(
            issue_number=issue.number,
            chunks=chunks,
            vectors=vectors,
            title=issue.title,
            state=issue.state,
            url=issue.url,
            labels=issue.labels,
        )
        print(f"Issue #{issue.number} updated successfully")

        return End({"issue_number": issue.number, "chunks_indexed": len(chunks)})


@dataclass
class FetchAllIssuesNode(BaseNode[FetchAllIssuesState, None, dict]):
    """å…¨Issueå–å¾—ãƒãƒ¼ãƒ‰"""

    async def run(
        self, ctx: GraphRunContext[FetchAllIssuesState]
    ) -> Annotated[End[dict], Edge(label="å…¨Issueå–å¾—å®Œäº†")]:
        """GitHub APIã‹ã‚‰å…¨Issueæƒ…å ±ã‚’å–å¾—"""
        print(f"Fetching issues from {ctx.state.start} to {ctx.state.end}...")
        github_issue_tool = ctx.tools["github_issue"]
        issues = github_issue_tool.fetch_all_issues(ctx.state.start, ctx.state.end)

        ctx.state.fetched_issues = issues
        return End({"status": "success", "count": len(issues)})
